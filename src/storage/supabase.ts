import pMap from 'p-map'
import {z} from 'zod'
import {client, sql} from '~/db'
import {createProxyClient} from '~/openapi/client'
import {paths} from '~/openapi/generated/supabase-storage'

const Env = z.object({
  SUPABASE_PROJECT_URL: z.string().url(),
  SUPABASE_SERVICE_ROLE_KEY: z.string().min(1),
})

export const createStorageClient = () => {
  const supabaseEnv = Env.parse(process.env)
  return createProxyClient<paths>().configure({
    baseUrl: `${supabaseEnv.SUPABASE_PROJECT_URL}/storage/v1`,
    headers: {
      apikey: supabaseEnv.SUPABASE_SERVICE_ROLE_KEY,
      authorization: `Bearer ${supabaseEnv.SUPABASE_SERVICE_ROLE_KEY}`,
    },
  })
}

export type FileInfo = {
  entry: {entryName: string; getData: () => Buffer}
  aliases: string[]
  mimeType: string
}
export const insertFiles = async (dbArtifact: {id: string; created_at: Date}, fileInfo: FileInfo[]) => {
  const storage = createStorageClient()
  const datePrefix = [
    dbArtifact.created_at.toISOString().split(/\D/).slice(0, 3).join('/'), // date part in subfolders so when debugging can navigate to year/month/day
    dbArtifact.created_at.toISOString().split('T')[1].replaceAll(':', '.'), // time part as a dot-separated string
  ].join('/')

  fileInfo.forEach((f, i) => {
    const firstIndex = fileInfo.findIndex(o => f.entry.entryName === o.entry.entryName)
    if (firstIndex !== i) {
      console.error('Duplicate entry', f.entry.entryName, firstIndex, i, fileInfo)
      throw new Error(`Duplicate entry: ${f.entry.entryName}`)
    }
  })
  const files = await pMap(
    fileInfo,
    async ({entry, aliases, mimeType}) => {
      const file = await storage.object
        .bucketName('artifact_files')
        .wildcard(`artifacts/${datePrefix}/${dbArtifact.id}/${entry.entryName}`)
        .post({content: {[mimeType]: entry.getData()}})

      return {file, aliases}
    },
    {concurrency: 10},
  )

  const inserts = await client.any(sql<queries.FileAlias>`
    insert into file_aliases (alias, artifact_id, object_id)
    select alias, artifact_id, object_id
    from jsonb_populate_recordset(
      null::file_aliases,
      ${JSON.stringify(
        files.flatMap(f => {
          return f.aliases.flatMap(alias => ({
            alias,
            artifact_id: dbArtifact.id,
            object_id: f.file.json.Id,
          }))
        }),
      )}
    )
    on conflict (alias, object_id) do nothing
    returning *
  `)

  return {files, inserts}
}

/** Searches for a file by its alias, and if found, fetches from supabase storage */
export const loadFile = async (filepath: string) => {
  const storage = createStorageClient()
  const dbFile = await client.maybeOne(sql<queries.DbFile>`
    select fa.object_id, o.name as storage_pathname
    from file_aliases fa
    join storage.objects o on fa.object_id = o.id::text
    where alias = ${filepath}
    and o.name is not null
    order by fa.created_at desc
    limit 1
  `)

  if (!dbFile || !dbFile.storage_pathname) {
    return null
  }

  const file = await storage.object.bucketName('artifact_files').wildcard(dbFile.storage_pathname).get()
  return {pathname: dbFile.storage_pathname, object: file}
}

export declare namespace queries {
  // Generated by @pgkit/typegen

  /** - query: `insert into file_aliases (alias, artifac... [truncated] ...alias, object_id) do nothing returning *` */
  export interface FileAlias {
    /** column: `public.file_aliases.id`, not null: `true`, regtype: `prefixed_ksuid` */
    id: import('~/db').Id<'file_aliases'>

    /** column: `public.file_aliases.alias`, not null: `true`, regtype: `text` */
    alias: string

    /** column: `public.file_aliases.object_id`, not null: `true`, regtype: `text` */
    object_id: string

    /** column: `public.file_aliases.created_at`, not null: `true`, regtype: `timestamp with time zone` */
    created_at: Date

    /** column: `public.file_aliases.updated_at`, not null: `true`, regtype: `timestamp with time zone` */
    updated_at: Date

    /** column: `public.file_aliases.artifact_id`, not null: `true`, regtype: `prefixed_ksuid` */
    artifact_id: string
  }

  /** - query: `select fa.object_id, o.name as storage_p... [truncated] ...null order by fa.created_at desc limit 1` */
  export interface DbFile {
    /** column: `public.file_aliases.object_id`, not null: `true`, regtype: `text` */
    object_id: string

    /** column: `storage.objects.name`, regtype: `text` */
    storage_pathname: string | null
  }
}
