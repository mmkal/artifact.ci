name: upload artifact action
description: Drop in replacement for actions/upload-artifact which provides a browsable link to the artifact
inputs:
  path:
    description: A file, directory or wildcard pattern that describes what to upload
    required: true
  name:
    description: Name of the artifact to upload
    required: false
    default: artifact
  origin:
    description: The origin of the server to upload the artifact to
    required: false
    default: https://www.artifact.ci
  github-token:
    description: The GitHub token to use for the upload
    required: false
runs:
  using: composite
  steps:
    - shell: bash
      run: echo "::group::Upload artifact"
    - name: upload
      uses: actions/upload-artifact@v4
      with:
        name: ${{ inputs.name }}
        path: ${{ inputs.path }}
    - name: print url
      shell: bash
      run: |
        echo 'View your artifact here:'
        echo '${{ inputs.origin }}/artifact/browse/${{ github.repository }}/${{ github.run_id }}/${{ inputs.name }}'
    - name: Checkout artifact.ci
      uses: actions/checkout@v4
      with:
        repository: mmkal/artifact.ci
        path: tmp/artifact.ci
    - name: install
      shell: bash
      run: corepack enable && pnpm install --silent
      working-directory: tmp/artifact.ci
    - name: patch @vercel/blob for debugging
      shell: bash
      working-directory: tmp/artifact.ci
      run: |
        node -v
        sed -i 's/const res = await _undici.fetch.call/console.log("client.cjs fetching", {url, options, event});const res = await _undici.fetch.call/g' node_modules/@vercel/blob/dist/client.cjs
        vercel_chunk_name=$(ls node_modules/@vercel/blob/dist | grep chunk | grep .cjs | grep -v .map)
        vercel_chunk_cjs="node_modules/@vercel/blob/dist/$vercel_chunk_name"
        echo "vercel_chunk_cjs: >>>$vercel_chunk_cjs<<<"
        sed -i 's/const apiResponse/const logFetch = (...args) => {console.log("apiResponse fetching", ...args, {a: args[1]?.headers?.authorization?.split(" ")}); return _undici.fetch(...args)}; const apiResponse/g' $vercel_chunk_cjs
        sed -i 's/_undici.fetch.call/logFetch.call/g' $vercel_chunk_cjs
        sed -i 's/res.ok/(res.ok || console.log(await res.clone().text(), res.url, res.status))/g' node_modules/@vercel/blob/dist/client.cjs
        sed -i 's/return clientToken/console.log({clientToken}); return clientToken/g' node_modules/@vercel/blob/dist/client.cjs
    - name: upload blob
      uses: actions/github-script@v6
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
      with:
        script: |-
          const cwd = process.cwd()
          process.chdir('tmp/artifact.ci')
          const inputs = ${{ toJson(inputs) }}
          process.chdir(cwd)
          async function doupload({context,glob,inputs}){const cwd=process.cwd();process.chdir("tmp/artifact.ci");const{lookup:mimeTypeLookup}=await import("mime-types").then(n=>{const e="default";return n[e]&&typeof n[e]=="object"&&"__esModule"in n[e]?n[e]:n});const fs=await import("fs/promises").then(n=>{const e="default";return n[e]&&typeof n[e]=="object"&&"__esModule"in n[e]?n[e]:n});const{upload,put}=await import("@vercel/blob/client").then(n=>{const e="default";return n[e]&&typeof n[e]=="object"&&"__esModule"in n[e]?n[e]:n});process.chdir(cwd);const githubToken=inputs["github-token"];const pathPrefix="${{ github.repository }}/${{ github.run_id }}/"+inputs.name;Object.assign(global,{window:{location:new URL(inputs.origin)}});const stat=await fs.stat(inputs.path).catch(e=>{if(e.code==="ENOENT")return null;throw e});const globPattern=stat?.isDirectory()?`${inputs.path}/**/*`:inputs.path;if(Math.random()){const globber2=await glob.create(globPattern);const files=await globber2.glob();const bulkRequest={type:"bulk",files:files.map(f=>{const pathname=pathPrefix+f.replace(process.cwd(),"");return{pathname}}),callbackUrl:`${inputs.origin}/artifact/upload/signed-url`,clientPayload:{githubToken,commit:{ref:context.ref,sha:context.sha,actions_run_id:context.runId.toString()},context}};const res=await fetch(`${inputs.origin}/artifact/upload/signed-url`,{method:"POST",body:JSON.stringify(bulkRequest),headers:{"Content-Type":"application/json","User-Agent":"artifact.ci/action"}});const data=await res.json();console.log("data::::",data)}const results={};const globber=await glob.create(globPattern);for await(const filepath of globber.globGenerator()){const fileStat=await fs.stat(filepath);if(fileStat.isDirectory())continue;const blobPath=pathPrefix+filepath.replace(process.cwd(),"");const content=await fs.readFile(filepath);const result=await upload(blobPath,content,{access:"public",handleUploadUrl:"/artifact/upload/signed-url",contentType:mimeTypeLookup(filepath)||"text/plain",clientPayload:JSON.stringify({githubToken,commit:{ref:context.ref,sha:context.sha,actions_run_id:context.runId}})});results[blobPath]=result}if(Object.keys(results).length===0){throw new Error("no files uploaded")}console.log(`View your files here:`);Object.keys(results).forEach(blobPath=>{console.log(`${inputs.origin}/artifact/blob/${blobPath}`)})}
          await doupload({context, glob, inputs})
    - name: cleanup
      shell: bash
      run: rm -rf tmp/artifact.ci
